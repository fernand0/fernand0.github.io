---
layout: post
title: "Las amenazas en los tiempos de la IA"
date: "2024-07-29 15:00:00 +0000"
category: seguridad
tags:
- web
- WordPress
imagefeature: "https://live.staticflickr.com/220/446493967_c97d84a7f4_z.jpg"
---

<a data-flickr-embed="true" href="https://www.flickr.com/photos/fernand0/446493967/in/photolist-4MBdM6-5wd7kj-Fsp6R" title="Secadores amenazantes"><img src="https://live.staticflickr.com/220/446493967_c97d84a7f4_z.jpg" width="640" height="480" alt="Secadores amenazantes"/></a><script async src="//embedr.flickr.com/assets/client-code.js" charset="utf-8"></script>

Hace unos meses podíamos leer [Staying ahead of threat actors in the age of AI](https://www.microsoft.com/en-us/security/blog/2024/02/14/staying-ahead-of-threat-actors-in-the-age-of-ai/) que me gustó porque nos da algunas pistas de algunos de los aspectos peligrosos de la inteligencia artificial, desde el punto de vista de la seguridad informática.

Proporcionan una lista de diversas organizaciones que aparecen frecuentemente en diversos ataques y los usos que han observado de la inteligencia artificial para estos fines.
No entraremos en esos detalles (aunque puede ser interesante echar un ojo) sino que nos centraremos en el final del artículo, donde se hace un resumen.

* Reconocimiento (**LLM-informed reconnaissance**): esto es, obtener información sobre tecnologías y vulnerabilidades.
* Mejora de los programas (**LLM-enhanced scripting techniques**): se pueden utilizar los modelos de lenguaje grandes para generar programas o mejorar los que ya tenemos.
* Desarrollo asistido de programas (**LLM-aided development:**): parecido al anterior, pero ya integrado en el ciclo de vida de nuestros desarrollos.
* Ingeniería social mejorada (**LLM-supported social engineering**): se puede usar para mejorar las traducciones y los mensajes que se utilizan para manipular a los objetivos.
* Investigación de vulnerabilidades asistida (**LLM-assisted vulnerability research**): utilizar estos sistemas para comprender mejor las vulnerabilidades en los programas y en los sistemas.
* Optimización del desarrollo de *payloads* (**LLM-optimized payload crafting**): seguimos con ideas parecidas, cuando necesitamos generar o mejorar algún trozo de código que utilizaremos en un ataque.
* Evasión mejorada de los sistemas de detección de anomalías (**LLM-enhanced anomaly detection evasion**): ayuda para tratar de hacer pasar nuestros ataques dentro de la actividad normal de nuestro objetivo.
* Saltar las características de seguridad (**LLM-directed security feature bypass**): ayuda en la búsqueda de formas de evitar los mecanismos de seguridad (doble factor, CAPTCHAS, ...)
* Recomendaciones en el desarrollo de recursos (**LLM-advised resource development:**): no sólo desarrollo de herramientas, sino también modificación e incluso planificación estratégica.

Interesante.




